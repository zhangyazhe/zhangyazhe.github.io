<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  
  
    <meta name="keywords" content="课程笔记, 算法, 随笔, git, linux, Qt, Java, Big Data">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <title>
    Big Data Note |
    
    知 昂 张</title>
  
    <link rel="shortcut icon" href="/favicon.ico">
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<script src="/js/pace.min.js"></script>

<meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="知 昂 张" type="application/atom+xml">
</head>

<body>
<main class="content">
  <section class="outer">
  

<article id="post-Big-Data-Note" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal>
  
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Big Data Note
    </h1>
  
  




      </header>
    

    
      <div class="article-meta">
        <a href="/2020/03/21/Big-Data-Note/" class="article-date">
  <time datetime="2020-03-21T13:55:53.000Z" itemprop="datePublished">2020-03-21</time>
</a>
        
      </div>
    

    
      
    <div class="tocbot"></div>





    

    <div class="article-entry" itemprop="articleBody">
      


      

      
        <p>摘要：</p>
<p>hadoop、Kafka、Flink<br>持续更新中…</p>
<a id="more"></a>

<h2 id="学习计划"><a href="#学习计划" class="headerlink" title="学习计划"></a>学习计划</h2><h3 id="Hadoop（3月20日-4月13日左右-20-25天）"><a href="#Hadoop（3月20日-4月13日左右-20-25天）" class="headerlink" title="Hadoop（3月20日~4月13日左右 20-25天）"></a>Hadoop（3月20日~4月13日左右 20-25天）</h3><ul>
<li><p>学习资料</p>
<ol>
<li>hadoop入门实战手册（计划用时8天） <a href="https://vdisk.weibo.com/s/aprYE9iSa5XEs" target="_blank" rel="noopener">https://vdisk.weibo.com/s/aprYE9iSa5XEs</a></li>
<li>大数据技术原理与应用慕课（计划用时8天） <a href="https://www.icourse163.org/course/XMU-1002335004" target="_blank" rel="noopener">https://www.icourse163.org/course/XMU-1002335004</a></li>
<li>MapReduce编程实践 <a href="http://dblab.xmu.edu.cn/blog/2481-2/" target="_blank" rel="noopener">http://dblab.xmu.edu.cn/blog/2481-2/</a></li>
<li>HDFS编程实践 <a href="http://dblab.xmu.edu.cn/blog/2481-2/" target="_blank" rel="noopener">http://dblab.xmu.edu.cn/blog/2481-2/</a></li>
<li>Hadoop源代码分析 <a href="https://vdisk.weibo.com/s/bef7_LzOlZB5" target="_blank" rel="noopener">https://vdisk.weibo.com/s/bef7_LzOlZB5</a></li>
</ol>
</li>
<li><p>时间安排</p>
<p>工作日每天至少一小时，双休日每天至少两小时</p>
</li>
</ul>
<h3 id="Kafka（4月13日-5月5日左右-20-25天）"><a href="#Kafka（4月13日-5月5日左右-20-25天）" class="headerlink" title="Kafka（4月13日~5月5日左右 20-25天）"></a>Kafka（4月13日~5月5日左右 20-25天）</h3><h3 id="Flink（5月5日-6月底-20-25天）"><a href="#Flink（5月5日-6月底-20-25天）" class="headerlink" title="Flink（5月5日~6月底 20-25天）"></a>Flink（5月5日~6月底 20-25天）</h3><h3 id="SpringBoot（6月底-实习前-20-25天）"><a href="#SpringBoot（6月底-实习前-20-25天）" class="headerlink" title="SpringBoot（6月底~实习前 20-25天）"></a>SpringBoot（6月底~实习前 20-25天）</h3><h2 id="学习目标"><a href="#学习目标" class="headerlink" title="学习目标"></a>学习目标</h2><ul>
<li><p>搭建hadoop、flink、kafka系统并了解这3个开源系统的原理，达到可以流畅部署，可以基本上理解核心逻辑，比如了解flink作业启动过程、flink作业运行时处理过程、kafka系统数据写入过程、数据持久化过程、数据消费过程、hadoop系统hdfs数据写入过程、数据持久化过程、数据读取过程、主控fsimage数据结构、yarn队列原理</p>
</li>
<li><p>使用taf-java构造数据实时写入数据到kafka，flink从kafka消费数据进行计算，然后把数据写入到mysql，可以计算一个网站常用的指标，比如UV、PV、DAU等指标。</p>
</li>
<li><p>重点看Hadoop，Kafka，flink这3个组件，可以在云上买一些服务器搭建或者虚拟出多台服务器搭建环境，把这些组件代码也download下来，结合源码学习</p>
</li>
<li><p>开发语言主要是java，然后是go和python开发一些工具，RPC框架是使用taf，这个框架已经开源，外部叫tars，可以基于tars来搭建开发环境，java的java springboot也需要学习</p>
</li>
</ul>
<h2 id="hadoop"><a href="#hadoop" class="headerlink" title="hadoop"></a>hadoop</h2><ul>
<li><p>hadoop两大核心组件：HDFS和MapReduce</p>
</li>
<li><p>MapReduce两大核心组件：JobTracker和TaskTraker</p>
<p>前者对整个作业任务进行管理，会把用户的大作业拆分成很多的小作业，每一个小作业在一个机器上执行，这个机器上的小作业就由部署在该机器的TaskTraker进行追踪和执行。</p>
</li>
<li><p>DataNode和TaskTraker可以部署在同一台机器上</p>
</li>
</ul>
<h2 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h2><ul>
<li><p>块的概念：与普通文件系统中块的概念类似，但是HDFS中的块会大很多。如果块太小的话，块的数量就会很多，后续的寻址开销就会很大。通过块的设计，将一个大文件拆分成若干的块，如此便可以存储在不同的机器上。每个块的大小是固定的，也方便对数据进行管理。</p>
</li>
<li><p>HDFS中的NamaNode和DataNode</p>
<ul>
<li><p>NameNode用来记录文件的每一个部分都被存储在了哪台机器上面，DataNode用来实际存储数据。NameNode中存储的是元数据，元数据记录了文件是什么、文件被分成多少块、每个块和文件是怎么映射的、每个块被存储到那个服务器上面等等信息。</p>
</li>
<li><p>元数据有两个关键的数据结构：FsImage和Editlog。</p>
<p>FsImage用来保存系统文件树以及文件树中所有的文件和文件夹中的元数据。其中包括文件的复制等级、修改和访问时间、访问权限、块大小以及组成文件的块。但是，每个块具体没存储在哪个节点的信息不是由FsImage保存的。</p>
<p>EditLog用来记录对数据进行的操作。</p>
<p>在NameNode工作起来的时候，FsImage中的存的是历史数据，而EditLog中存的是对历史数据所有的操作。首先需要根据F中的历史数据以及E中记录的操作，得到最新的元数据信息。NameNode会把最新元数据的F保存下来，然后把旧版的删掉，同时再创建一个新的空的E。之后，在对数据进行操作的时候，因为F比较大，如果每次都去操作F的话，效率很低。所以我们只是将更新的操作存到E里面。</p>
</li>
<li><p>在NN（NameNode）工作过程中，E会不断变大。这时候，每间隔一段时间，SecondaryNameNode（第二名称节点）会让主N停止向E中写东西，同时将主N的F和E都通过HTTP的方式下载过来。在这个过程中，主N会将新的操作记录在edit.new中。第二N会根据F和E合并出新的F，再将新的F发给主N。然后主N会将edit.new更改成新的E。这样就既解决了E不断变大的问题，同时实现了第二N的冷备份。</p>
</li>
</ul>
</li>
<li><p>HDFS HA</p>
<p>HDFS2.0引入HDFS HA的概念，我们的名字节点将不止一个，其中有一个活跃名字节点和一个待命名字节点，具体哪个活跃哪个待命由zookeeper进行管理。当活跃名字节点出现故障是，待命名字节点可以立刻顶上去。要做到这一点，必须保证活跃名字节点和待命名字节点储存的元数据等等数据都是实时同步的。Editlog的同步是通过名字节点之间的共享存储系统进行同步的，对于映射表信息（例如一个节点包括几个块，某个快被存储到哪个节点上）的实时同步，是通过底层的数据节点一直都同时向活跃名字节点和待命名字节点汇报来进行维护的</p>
</li>
<li><p>HDFS Federation</p>
<p>先前的HDFS架构仅允许整个群集使用单个命名空间，单个Namenode管理命名空间。 HDFS Federation通过向HDFS添加对多个Namenodes /Namespaces的支持来解决此限制，每个名字空间各自独立地管理自己的命名空间。每个DataNode要向集群中所有的namenode注册，且周期性的向所有namenode发送心跳和块报告，并执行来自所有namenode的命令，所以所有的名字节点都是共享底层的数据节点的。</p>
<p>每个命名空间都有一个块池，块池是属于单个命名空间的一组块。 Datanode存储集群中所有块池的块。 每个Block Pool都是独立管理的。 这允许命名空间为新块生成块ID，而无需与其他命名空间协调。</p>
<p>访问数据时，就相当于每个名字节点是一个文件夹，我要访问哪个名字节点的数据，就去访问哪个文件夹。</p>
<p>Federation提高了HDFS的集群扩展性，同时各个名字节点可以同时对外提供服务，提高了吞吐率。再就是数据的隔离性，可以将不同业务类型的数据放在不同的名字节点进行管理。</p>
</li>
<li><p>HDFS存储原理</p>
<p>通常来讲，所有的数据块都会被存放3份，也就是冗余数据，用来保证一个数据出问题后，还可以恢复。三个块不会存储在同一个节点内。对于第一个块，如果这个块是某一个集群内部的某一个节点产生的，那么就会吧这个快存放在这个节点上。如果这个块是外部产生的，HDFS会选一个比较空闲的节点来存放数据；对于第二个块，会放在不同机架上的某一个节点。对于第三个块，会放在和第一个节点相同的机架上面的不同节点上面。（集群中有很多机架，每个机架上有很多节点，同一机架的节点之间的数据传输带宽是很高的）</p>
</li>
<li><p>HDFS读取原理</p>
<p>读取时，理论上可以从之前存储的任意一个冗余的块中进行读取。但是一般会采取就近原则。HDFS提供一个API，可以算出数据所在的机架UD，也算出需要读取数据的节点的机架ID，这样就可以选一个比较近的进行读取。</p>
</li>
<li><p>HDFS数据读写原理 <a href="https://blog.csdn.net/u014470581/article/details/51461540" target="_blank" rel="noopener">https://blog.csdn.net/u014470581/article/details/51461540</a></p>
</li>
<li><p>HDFS编程</p>
<p>使用java进行编程。首先需要将/usr/local/hadoop/share/hadoop中的commonjar包进行导入</p>
<p>然后还需要将/hadoop/etc/hadoop中的core-site.xml和hdfs-site.xml文件拷贝到当前的java工程目录（bin）下</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration; <span class="comment">//他的实例化对象会包含hadoop的配置信息</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem; <span class="comment">//其实例为HDFS实例</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;<span class="comment">//路径要用这个表示</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Chapter3</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">	String filename = <span class="string">"hdfs://localhost:9000/user/hadoop/test.txt"</span>;</span><br><span class="line">	Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">	FileSystem fs = FileSystem.get(conf); </span><br><span class="line">  <span class="keyword">if</span>(fs.exists(<span class="keyword">new</span> Path(filename)))&#123;</span><br><span class="line">		System.out.println(<span class="string">"文件存在"</span>); &#125;</span><br><span class="line">  <span class="keyword">else</span>&#123;</span><br><span class="line">		System.out.println(<span class="string">"文件不存在"</span>); &#125;</span><br><span class="line">	&#125; <span class="keyword">catch</span> (Exception e) &#123; </span><br><span class="line">  	e.printStackTrace();</span><br><span class="line">	&#125; </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h2><ul>
<li><p>基本原理：分而治之</p>
</li>
<li><p>计算向数据靠拢：寻找离数据块最近的map机器对数据进行处理</p>
</li>
<li><p>Master/Slave架构</p>
<p>包含一个Master服务器，上面运行作业跟踪器JobTracker，负责整个作业的调度和处理以及失败的恢复。另外包含若干个slave服务器，上面运行负责具体任务执行的TaskTracker，负责接收JobTracker给他发的作业处理指令，完成具体的任务处理。</p>
</li>
<li><p>MR的体系结构</p>
<ul>
<li><p>Client</p>
<p>提交任务给JobTracker</p>
</li>
<li><p>JobTracker</p>
<p>负责资源监控、检测各个TaskTracker的运行情况、一旦检测到错误，就把这个任务分配到其他节点继续执行。</p>
<p>这些信息也会被JobTracker发送给Task scheduler</p>
</li>
<li><p>Task scheduler</p>
<p>负责任务分配，决定哪个任务应该分配给哪个节点</p>
</li>
<li><p>TaskTracker</p>
<p>执行具体任务</p>
<p>把自己的资源使用情况以及任务执行进度通过心跳的方式反馈给JobTracker</p>
<p>资源会被分为一个个的槽（slot），资源以slot的方式分配出去。slot会被分为map slot和reduce slot用于执行不同的任务</p>
<p>在一台机器上可以同时执行map任务和reduce任务</p>
</li>
</ul>
</li>
<li><p>MR的工作流程</p>
<ul>
<li>HDFS中的数据会被分片，然后为每一个小分片启动一个map任务，map任务的输入时一个键值对，输出时很多键值对。map任务执行的结果要分发给reduce任务，类似于神经网络从一层传数据给下一层。要吧map任务的输出分为几类取决于接下来有多少reduce节点。比如有三个reduce节点，那么每个map都会吧自己的输出结果分为三类，这个过程叫做shuffle，shuffle结束之后，才会吧结果发送给reduce。reduce结束之后，再把结果输出到HDFS中去。</li>
</ul>
</li>
<li><p>MapReduce各个执行阶段及Shuffle过程详解 <a href="https://blog.csdn.net/zhengwei223/article/details/78304764" target="_blank" rel="noopener">https://blog.csdn.net/zhengwei223/article/details/78304764</a></p>
<ul>
<li>分片过多会导致map任务多，资源消耗大。分片太少会使得并行度降低。</li>
<li>map任务数量去觉得分片的数量，reduce任务的数量取决于整个集群中 reduce slot可用资源总数，一班reduce任务数会比这个资源总数略小</li>
<li>Map任务的输入是<key-value>键值对，map任务处理完之后经过shuffle过程会生成若干的key-value list作为reduce任务的输入，reduce处理后输出的依然是K-V.</li>
</ul>
</li>
<li><p>MR的整个过程，数据一开始从HDFS中读取，最终写入HDFS。中间产生的中间结果不会写入HDFS而是存在各个机器自己的磁盘中。</p>
</li>
<li><p>MR不是万能的，只有当一个大的任务可以拆分成若干小的任务而且各个任务之间不会相互依赖才可以用MR。</p>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2020/03/21/Big-Data-Note/" data-id="ck8q1u3g400002gie3ntybhq5"
         class="article-share-link">Share</a>
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Big-Data/" rel="tag">Big Data</a></li></ul>

    </footer>

  </div>

  
    
  <nav class="article-nav">
    
      <a href="/2020/04/01/csp-201512-4-%E9%80%81%E8%B4%A7/" class="article-nav-link">
        <strong class="article-nav-caption">Newer</strong>
        <div class="article-nav-title">
          
            csp 201512_4 送货
          
        </div>
      </a>
    
    
      <a href="/2020/03/21/csp-201509-4-%E9%AB%98%E9%80%9F%E5%85%AC%E8%B7%AF/" class="article-nav-link">
        <strong class="article-nav-caption">Older</strong>
        <div class="article-nav-title">csp 201509_4 高速公路</div>
      </a>
    
  </nav>


  

  
    
  <div class="gitalk" id="gitalk-container"></div>
  
<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">

  
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

  
<script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script>

  <script type="text/javascript">
    var gitalk = new Gitalk({
      clientID: '77424c281e336f5d09b3',
      clientSecret: '7d8c854fef95db82c20d7e4820001abd45995754',
      repo: 'zyz_talk',
      owner: 'zhangyazhe',
      admin: ['zhangyazhe'],
      // id: location.pathname,      // Ensure uniqueness and length less than 50
      id: md5(location.pathname),
      distractionFreeMode: false,  // Facebook-like distraction free mode
      pagerDirection: 'last'
    })

  gitalk.render('gitalk-container')
  </script>

    
  <div class="gitalk" id="gitalk-container"></div>
  
<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">

  
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

  
<script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script>

  <script type="text/javascript">
    var gitalk = new Gitalk({
      clientID: '77424c281e336f5d09b3',
      clientSecret: '7d8c854fef95db82c20d7e4820001abd45995754',
      repo: 'zyz_talk',
      owner: 'zhangyazhe',
      admin: ['zhangyazhe'],
      // id: location.pathname,      // Ensure uniqueness and length less than 50
      id: md5(location.pathname),
      distractionFreeMode: false,  // Facebook-like distraction free mode
      pagerDirection: 'last'
    })

  gitalk.render('gitalk-container')
  </script>

  

</article>



</section>
  <footer class="footer">
  <div class="outer">
    <div class="float-right">
      <ul class="list-inline">
  
    <li><i class="fe fe-smile-alt"></i> <span id="busuanzi_value_site_uv"></span></li>
  
    <li><i class="fe fe-bookmark"></i> <span id="busuanzi_value_page_pv"></span></li>
  
</ul>
    </div>
    <ul class="list-inline">
      <li>&copy; 2020 知 昂 张</li>
      <li>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></li>
      <li>Theme  <a href="https://github.com/zhwangart/hexo-theme-ocean" target="_blank" rel="noopener">Ocean</a></li>
    </ul>
  </div>
</footer>

</main>
<aside class="sidebar">
  <button class="navbar-toggle"></button>
<nav class="navbar">
  
    <div class="logo">
      <a href="/"><img src="/images/head.svg" alt="知 昂 张"></a>
    </div>
  
  <ul class="nav nav-main">
    
      <li class="nav-item">
        <a class="nav-item-link" href="/">Home</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/archives">Archives</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/gallery">Gallery</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/about">About</a>
      </li>
    
    <li class="nav-item">
      <a class="nav-item-link nav-item-search" title="Search">
        <i class="fe fe-search"></i>
        Search
      </a>
    </li>
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      <div class="totop" id="totop">
  <i class="fe fe-rocket"></i>
</div>
    </li>
    <li class="nav-item">
      
        <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
          <i class="fe fe-feed"></i>
        </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
</aside>

<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/jquery.justifiedGallery.min.js"></script>


<script src="/js/lazyload.min.js"></script>


<script src="/js/busuanzi-2.3.pure.min.js"></script>


  
<script src="/fancybox/jquery.fancybox.min.js"></script>




  
<script src="/js/tocbot.min.js"></script>

  <script>
    // Tocbot_v4.7.0  http://tscanlin.github.io/tocbot/
    tocbot.init({
      tocSelector: '.tocbot',
      contentSelector: '.article-entry',
      headingSelector: 'h1, h2, h3, h4, h5, h6',
      hasInnerContainers: true,
      scrollSmooth: true,
      positionFixedSelector: '.tocbot',
      positionFixedClass: 'is-position-fixed',
      fixedSidebarOffset: 'auto',
    });
  </script>



<script src="/js/ocean.js"></script>


</body>
</html>